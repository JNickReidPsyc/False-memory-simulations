{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "263fccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import stanza\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01489fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a0ff0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "10281c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punctuation(x):\n",
    "    x = [i for i in x if i not in string.punctuation]\n",
    "    x = ''.join(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4f9511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_sq(x, y):\n",
    "    cor = scipy.stats.pearsonr(x, y)\n",
    "    return cor[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ad007d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vec(vec):\n",
    "    sq_vec = vec**2\n",
    "    sum_sq = np.sum(sq_vec)\n",
    "    mag = np.sqrt(sum_sq)\n",
    "    normed_vec = vec / mag\n",
    "    return normed_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e7353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(mat):\n",
    "    sq_mat = mat**2\n",
    "    sum_sq = np.sum(sq_mat, axis=1)\n",
    "    mag = np.sqrt(sum_sq)\n",
    "    mag[mag == 0] = 1\n",
    "    normed_mat = np.transpose((np.transpose(mat) / mag))\n",
    "    return normed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ba9809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_memory(word_list):\n",
    "    mem_matrix = []\n",
    "    for i in word_list:\n",
    "        mem_matrix.append(word_matrix[word_dic[i]])\n",
    "    mem_matrix = np.array(mem_matrix)\n",
    "    return mem_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2417dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo_intensity(probes, memory, tau=3):\n",
    "    normed_memory = normalize_matrix(memory)\n",
    "    similarities = probes @ np.transpose(normed_memory)\n",
    "    if tau == 2:\n",
    "        activations = similarities*(abs(similarities))\n",
    "    if tau == 4:\n",
    "        activations = similarities*(abs(similarities))*similarities*(abs(similarities))\n",
    "    else:\n",
    "        activations = similarities**tau\n",
    "    activations = np.sum(activations, axis=1)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d8757b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('R&M1995.csv') as f:\n",
    "    df = list(csv.reader(f))\n",
    "df = df[1:]\n",
    "all_drm_words = []\n",
    "for i in df:\n",
    "    all_drm_words.append(i[0])\n",
    "    word = i[1].split(', ')\n",
    "    for j in word:\n",
    "        all_drm_words.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5da10539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_stims(df):\n",
    "    crit_lures = []\n",
    "    crit_unrelated = []\n",
    "    old = []\n",
    "    unrelated = []\n",
    "    num = [i for i in range(0,24)]\n",
    "    random.shuffle(num)\n",
    "    df_presented = []\n",
    "    df_not_presented = []\n",
    "    for i in num[0:5]:\n",
    "        df_presented.append(df[i])\n",
    "    for i in num[5:10]:\n",
    "        df_not_presented.append(df[i])\n",
    "    for i in df_presented:\n",
    "        crit_lures.append(i[0])\n",
    "        items = i[1].split(', ')\n",
    "        for j in items:\n",
    "            old.append(j)\n",
    "    for i in df_not_presented:\n",
    "        crit_unrelated.append(i[0])\n",
    "        items = i[1].split(', ')\n",
    "        for j in items:\n",
    "            unrelated.append(j)\n",
    "    drm_list = old + crit_lures + unrelated + crit_unrelated\n",
    "    return drm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7efcc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load LSA. These are the pre-trained vectors from Fritz Gunther's website. \n",
    "#downloadable from https://sites.google.com/site/fritzgntr/software-resources/semantic_spaces\n",
    "#The TASA matrix was converted for use in Python\n",
    "#word_dic includes all words in the corpus and is used to index the rows of the word matrix\n",
    "#word_matrix is a 92393 (words) by 300 (dimensions) numpy array\n",
    "import pickle\n",
    "with open('LSA word matrix april 19', 'rb') as f:\n",
    "    word_matrix = pickle.load(f)\n",
    "with open('LSA word dic april 19', 'rb') as f:\n",
    "    word_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "138f82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent):\n",
    "    parsed = sent.split(' ')\n",
    "    parsed = [i for i in parsed if i not in stoplist]\n",
    "    sent_vec = np.zeros(len(word_matrix[0]))\n",
    "    for i in parsed:\n",
    "        sent_vec += word_matrix[word_dic[i]]\n",
    "    sent_vec = normalize_vec(sent_vec)\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8bdc3",
   "metadata": {},
   "source": [
    "Simulation 1: Arndt and Hirshman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7606a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empirical means\n",
    "r_300 = np.array([.51, .61, .21, .28])\n",
    "r_500 = np.array([.60, .75, .17, .23])\n",
    "r_800 = np.array([.65, .72, .14, .18])\n",
    "r_3000 = np.array([.77, .76, .10, .16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a23c0ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemtype: ['target list/list item', 'target list/critical lure', 'foil list/list item', 'foil list/critical lure']\n",
      "means:  [0.789  0.7028 0.1542 0.1492]\n",
      "SDs:  [0.04098428 0.19243742 0.04100033 0.15355572]\n"
     ]
    }
   ],
   "source": [
    "# Simulation for 3000ms study rate (change l to simulate other study rates)\n",
    "l = 0.05\n",
    "t = 3\n",
    "p_old = 47\n",
    "sim_list = []\n",
    "for s in range(0, 1000):\n",
    "    stims = make_random_stims(df)\n",
    "    memory = make_memory(stims[0:75])\n",
    "    memory = memory * np.random.choice([0, 1], size=(len(memory), len(memory[0])), p=[1-l, l])\n",
    "    probes = make_memory(stims)\n",
    "    probes = normalize_matrix(probes)\n",
    "    familiarities = echo_intensity(probes, memory, tau=t)\n",
    "    criterion = np.percentile(familiarities, 100-p_old)\n",
    "    old_items = familiarities[0:75]\n",
    "    crit_lure = familiarities[75:80]\n",
    "    unrel_items = familiarities[80:155]\n",
    "    uncrit_items = familiarities[155:160]\n",
    "    old_hits = np.sum(old_items > criterion) / 75\n",
    "    crit_hits = np.sum(crit_lure > criterion) / 5\n",
    "    unrel_hits = np.sum(unrel_items > criterion) / 75\n",
    "    uncrit_hits = np.sum(uncrit_items > criterion) / 5\n",
    "    sim_list.append([old_hits, crit_hits, unrel_hits, uncrit_hits])\n",
    "means = np.mean(sim_list, axis=0)\n",
    "sds = np.std(sim_list, axis=0)\n",
    "print('itemtype:', ['target list/list item', 'target list/critical lure', 'foil list/list item', 'foil list/critical lure'])\n",
    "print('means: ', means)\n",
    "print('SDs: ', sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de899bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865007707615485"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R-squared for 3000ms study rate\n",
    "r_sq(r_3000, np.mean(sim_list, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b39bc",
   "metadata": {},
   "source": [
    "Simulation 2 : Bransford and Franks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b9aa314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "with open('BF1971Exp2.csv') as f:\n",
    "    reader = csv.reader(f, delimiter = ',')\n",
    "    for row in reader:\n",
    "        df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83f0cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_matrix(sent_list):\n",
    "    mem = []\n",
    "    for i in sent_list:\n",
    "        mem_vec = get_sent_vec(i)\n",
    "        mem.append(mem_vec)\n",
    "    mem = np.array(mem)\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d359141",
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition = []\n",
    "for i in df[1:]:\n",
    "    if i[2]=='1':\n",
    "        acquisition.append(i[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "399f281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fours = []\n",
    "threes = []\n",
    "twos = []\n",
    "ones = []\n",
    "noncase = []\n",
    "for i in df[1:]:\n",
    "    if i[2]=='0' and i[3]=='1':\n",
    "        if i[1]=='four':\n",
    "            fours.append(i[4])\n",
    "        if i[1]=='three':\n",
    "            threes.append(i[4])\n",
    "        if i[1]=='two':\n",
    "            twos.append(i[4])\n",
    "        if i[1]=='one':\n",
    "            ones.append(i[4])\n",
    "        if i[1]=='noncase':\n",
    "            noncase.append(i[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3948c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq = mem_matrix(acquisition)\n",
    "four = mem_matrix(fours)\n",
    "three = mem_matrix(threes)\n",
    "two = mem_matrix(twos)\n",
    "one = mem_matrix(ones)\n",
    "ncase = mem_matrix(noncase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51c67bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empirical means\n",
    "bf_emp = [3.395,  2.000,  1.405, -1.060, -4.240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83d20eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item type:  ['4' '3' '2' '1' 'NC']\n",
      "means:  [1.64219126 1.49089284 1.4090732  1.09290584 1.0119236 ]\n"
     ]
    }
   ],
   "source": [
    "#Tau = 3 simulation\n",
    "l = 0.6\n",
    "t = 3\n",
    "sim_list = []\n",
    "for s in range(0, 1000):\n",
    "    acq_mem = acq * np.random.choice([0, 1], size=(len(acq), len(acq[0])), p=[1-l, l])\n",
    "    four_echo = echo_intensity(four, acq_mem, tau=t)\n",
    "    three_echo = echo_intensity(three, acq_mem, tau=t)\n",
    "    two_echo = echo_intensity(two, acq_mem, tau=t)\n",
    "    one_echo = echo_intensity(one, acq_mem, tau=t)\n",
    "    noncase_echo = echo_intensity(ncase, acq_mem, tau=t)\n",
    "    sim_list.append([np.mean(four_echo), np.mean(three_echo), np.mean(two_echo), np.mean(one_echo), np.mean(noncase_echo)])\n",
    "print('item type: ', np.array(['4', '3', '2', '1', 'NC']))\n",
    "print('means: ', np.mean(sim_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6031ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224744512097227"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R-squared for Tau = 3 model\n",
    "r_sq(bf_emp, np.mean(sim_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81748776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item type:  ['4' '3' '2' '1' 'NC']\n",
      "means:  [0.41542668 0.35206077 0.33515607 0.23358504 0.12070609]\n"
     ]
    }
   ],
   "source": [
    "#Tau = 7 simulation\n",
    "l = 0.6\n",
    "t = 7\n",
    "sim_list = []\n",
    "for s in range(0, 1000):\n",
    "    acq_mem = acq * np.random.choice([0, 1], size=(len(acq), len(acq[0])), p=[1-l, l])\n",
    "    four_echo = echo_intensity(four, acq_mem, tau=t)\n",
    "    three_echo = echo_intensity(three, acq_mem, tau=t)\n",
    "    two_echo = echo_intensity(two, acq_mem, tau=t)\n",
    "    one_echo = echo_intensity(one, acq_mem, tau=t)\n",
    "    noncase_echo = echo_intensity(ncase, acq_mem, tau=t)\n",
    "    sim_list.append([np.mean(four_echo), np.mean(three_echo), np.mean(two_echo), np.mean(one_echo), np.mean(noncase_echo)])\n",
    "print('item type: ', np.array(['4', '3', '2', '1', 'NC']))\n",
    "print('means: ', np.mean(sim_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c36d337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982337193975938"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R-squared for Tau = 7 model\n",
    "r_sq(bf_emp, np.mean(sim_list, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24cb66",
   "metadata": {},
   "source": [
    "Simulation 3: Reid and Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "231d5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "with open('drmcmt.csv') as f:\n",
    "    reader = csv.reader(f, delimiter = ',')\n",
    "    for row in reader:\n",
    "        df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "baddb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "luredf = []\n",
    "with open('cmtlures.csv') as f:\n",
    "    reader = csv.reader(f, delimiter = ',')\n",
    "    for row in reader:\n",
    "        luredf.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bfeb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_new = []\n",
    "met_lure = []\n",
    "lit_lure = []\n",
    "for x in luredf:\n",
    "    if x[0] != '':\n",
    "        lure = x[0].lower()\n",
    "        lure = strip_punctuation(lure)\n",
    "        crit_new.append(lure)\n",
    "    if x[1] != '':\n",
    "        lure = x[1].lower()\n",
    "        lure = strip_punctuation(lure)\n",
    "        met_lure.append(lure)\n",
    "    if x[2] != '':\n",
    "        lure = x[2].lower()\n",
    "        lure = strip_punctuation(lure)\n",
    "        lit_lure.append(lure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f036a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lists = []\n",
    "for i in df[1:6]:\n",
    "    text = i[0].lower()\n",
    "    text = text.replace('?','.')\n",
    "    sentences = text.split('. ')\n",
    "    sentences[14] = sentences[14][0:-1]\n",
    "    sentences = [strip_punctuation(i) for i in sentences]\n",
    "    study_lists.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f8dd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_items = []\n",
    "for i in study_lists:\n",
    "    old_items.append(i[4].lower())\n",
    "    old_items.append(i[6].lower())\n",
    "    old_items.append(i[12].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "566feeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "studied_items = []\n",
    "for i in study_lists:\n",
    "    studied_items.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "830d76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"condo\" not in TASA. We replaced the word condo with \"condominium\" to maintain the same meaning\n",
    "lit_lure[5] = 'her condominium has three rooms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "78900300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eda9ba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(studied_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9070c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = mem_matrix(studied_items)\n",
    "old_probes = mem_matrix(old_items)\n",
    "crit_probes = mem_matrix(crit_new)\n",
    "met_probes = mem_matrix(met_lure)\n",
    "lit_probes = mem_matrix(lit_lure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "884fdf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empirical means\n",
    "emp_means = np.array([.5593, .2298, .0766, .0362])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a905f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6074 0.2168 0.064  0.0485]\n"
     ]
    }
   ],
   "source": [
    "l = .05\n",
    "t = 3\n",
    "p_old = 30\n",
    "sim_list = []\n",
    "for s in range(0, 1000):\n",
    "    updated_mem = mem * np.random.choice([0, 1], size=(len(mem), len(mem[0])), p=[1-l, l])\n",
    "    old_echos = echo_intensity(old_probes, updated_mem, tau=t)\n",
    "    crit_echos = echo_intensity(crit_probes, updated_mem, tau=t)\n",
    "    met_echos = echo_intensity(met_probes, updated_mem, tau=t)\n",
    "    lit_echos = echo_intensity(lit_probes, updated_mem, tau=t)\n",
    "    total_echos = []\n",
    "    total_echos.extend(old_echos)\n",
    "    total_echos.extend(crit_echos)\n",
    "    total_echos.extend(met_echos)\n",
    "    total_echos.extend(lit_echos)\n",
    "    total_echos = np.array(total_echos)\n",
    "    criterion = np.percentile(total_echos, 100-p_old)\n",
    "    old_hits = np.sum(old_echos > criterion) / 15\n",
    "    crit_hits = np.sum(crit_echos > criterion) / 5\n",
    "    met_hits = np.sum(met_echos > criterion) / 5\n",
    "    lit_hits = np.sum(lit_echos > criterion) / 10\n",
    "    sim_list.append([old_hits, crit_hits, met_hits, lit_hits])\n",
    "sim_list = np.array(sim_list)\n",
    "sim_means = np.mean(sim_list, axis=0)\n",
    "print(sim_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "920a9ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9947636109894209"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R-squared for model\n",
    "r_sq(emp_means, np.mean(sim_list, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
